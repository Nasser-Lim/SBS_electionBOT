from openai import OpenAI
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import os, re, io
import requests
from bs4 import BeautifulSoup

client = OpenAI(
    # This is the default and can be omitted
    api_key=st.secrets(["OPENAI_API_KEY"])
)

def download_and_store_df(file_id, key):
    """íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    if key not in st.session_state:
        download_url = f'https://drive.google.com/uc?export=download&id={file_id}'
        response = requests.get(download_url)
        df = pd.read_pickle(io.BytesIO(response.content))
        st.session_state[key] = df

# with st.spinner('ì´ì„  ì±—ë´‡ì´ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤..'):
#         # íŒŒì¼ IDë¥¼ ì‚¬ìš©í•œ ë‹¤ìš´ë¡œë“œ URL ìƒì„±
#         file_id_ì„ ê±°êµ¬ = '1KJw12xawMoOd1RWOSo0ib6PkydLdwYar'
#         file_id_ì„ ê±°ë²• = '1Wc_lP14JjbOUxuUgZPwdkXDB79ccVai3'
#         download_url_ì„ ê±°êµ¬ = f'https://drive.google.com/uc?export=download&id={file_id_ì„ ê±°êµ¬}'
#         download_url_ì„ ê±°ë²• = f'https://drive.google.com/uc?export=download&id={file_id_ì„ ê±°ë²•}'

#         # íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ (ì„ ê±°êµ¬)
#         response_ì„ ê±°êµ¬ = requests.get(download_url_ì„ ê±°êµ¬)
#         df_ì„ ê±°êµ¬ = pd.read_pickle(io.BytesIO(response_ì„ ê±°êµ¬.content))

#         # íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ (ì„ ê±°ë²•)
#         response_ì„ ê±°ë²• = requests.get(download_url_ì„ ê±°ë²•)
#         df_ì„ ê±°ë²• = pd.read_pickle(io.BytesIO(response_ì„ ê±°ë²•.content))

# Pickle íŒŒì¼ ë¡œë”©ì— with êµ¬ë¬¸ ì‚¬ìš©
# with open('2020small_district_embeddings.pkl', 'rb') as file:
#     df_ì„ ê±°êµ¬ = pd.read_pickle(file)

# Pickle íŒŒì¼ ë¡œë”©ì— with êµ¬ë¬¸ ì‚¬ìš©
# with open('election_info_embeddings.pkl', 'rb') as file:
#     df_ì„ ê±°ë²• = pd.read_pickle(file)

with st.sidebar:
    st.markdown("ğŸ¤–<strong>â€œì´ë ‡ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”!â€</strong>", unsafe_allow_html=True)
    st.markdown("""
    - ì„ì¢…ì„ì€ ì–´ë””ì„œ ì¶œë§ˆí–ˆë‹ˆ?
    - ê¹€ì€í˜œ í›„ë³´ì˜ ì¶œë§ˆ ì •ë³´ëŠ”?
    - ì›í¬ë£¡ì˜ í›„ë³´ ì •ë³´ ì•Œë ¤ì¤˜
    - ì„œìš¸ ë§ˆí¬ê°‘ í›„ë³´ë“¤ì€ ëˆ„êµ¬?
    - ì „ë¶ êµ°ì‚°ì—ì„œ ë‚˜ì˜¨ í›„ë³´ë“¤ì€?
    - ëŒ€ì „ ë™êµ¬ì˜ í›„ë³´ ë“±ë¡ ìƒí™©ì€?
    - ì„œìš¸ ì†¡íŒŒêµ¬ì— ì–´ë–¤ ì„ ê±°êµ¬ ìˆë‚˜?
    - ì‚¬ì „íˆ¬í‘œ ë‚ ì§œëŠ” ì–¸ì œì•¼?
    - íˆ¬í‘œí•  ë•Œ í•„ìš”í•œ ì¤€ë¹„ë¬¼ì€?
    - íˆ¬í‘œ ì‹œ ì‹ ë¶„ì¦ì„ ìƒì–´ë²„ë ¸ë‹¤ë©´?
    - ì„ ê±°ë²•ì´ ì •í•˜ëŠ” êµ­íšŒì˜ì› í›„ë³´ ìê²©ì€?
    - ì„ ê±°ìš´ë™ ê¸°ê°„ í›„ë³´ì˜ ê¸ˆí’ˆìˆ˜ìˆ˜ëŠ” ì–´ë–¤ ì²˜ë²Œ ë°›ë‚˜?
    - ì„ ê±°ì—ì„œ ë”¥í˜ì´í¬ ì˜ìƒì„ ì‚¬ìš©í•˜ë©´?
    - ì„ ê±°ì—¬ë¡ ì¡°ì‚¬ë¥¼ ê³µí‘œí•  ìˆ˜ ì—†ëŠ” ê²½ìš°ëŠ”? 
    """)

# í›„ë³´ì ì •ë³´ë¥¼ ë³´ë‹¤ ì´í•´í•˜ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ í¬ë§·ìœ¼ë¡œ ë³€í™˜
def format_candidate_info(response_json):
    items = response_json['response']['body']['items']['item']
    formatted_text = ""
    for item in items:
        formatted_text += f"ì´ë¦„: {item['name']} ({item['gender']}, {item['age']}ì„¸)\n"
        formatted_text += f"ì„ ê±°êµ¬: {item['sdName']} {item['sggName']}\n"
        formatted_text += f"ì •ë‹¹: {item['jdName']}\n"
        formatted_text += f"ì§ì—…: {item['job']}\n"
        formatted_text += f"êµìœ¡: {item['edu']}\n"
        formatted_text += f"ì£¼ìš” ê²½ë ¥: {item['career1']}, {item['career2']}\n"
        formatted_text += f"í›„ë³´ ë“±ë¡ì¼: {item['regdate']}\n"
        formatted_text += f"í›„ë³´ ë“±ë¡ìƒíƒœ: {item['status']}\n\n"
    return formatted_text

def get_candidate_info(sggName, sdName):
    # API ìš”ì²­ ì£¼ì†Œ
    url = "http://apis.data.go.kr/9760000/PofelcddInfoInqireService/getPoelpcddRegistSttusInfoInqire"
    
    # íŒŒë¼ë¯¸í„° ì„¤ì •
    params = {
        "serviceKey": "klnPMx6BcJRvXEqdyooFTB4iLH1XwVLiIQPlcXxK2BGGGx7zR/R37T5SYr9a9GG3okt5Wpg63CnIJrsD6nG07g==",
        "pageNo": "1",  # í˜ì´ì§€ ë²ˆí˜¸
        "numOfRows": "10",  # í•œ í˜ì´ì§€ ê²°ê³¼ ìˆ˜
        "resultType": "json",
        "sgId": "20240410",  # ì„ ê±°ID
        "sgTypecode": "2",  # ì„ ê±°ì¢…ë¥˜ì½”ë“œ
        "sggName": sggName,  # í•¨ìˆ˜ ì…ë ¥ìœ¼ë¡œ ë°›ì€ ì„ ê±°êµ¬ëª…
        "sdName": sdName  # í•¨ìˆ˜ ì…ë ¥ìœ¼ë¡œ ë°›ì€ ì‹œë„ëª…
    }
    
    # API í˜¸ì¶œ
    response = requests.get(url, params=params)
    
    # ì‘ë‹µ ê²°ê³¼ í™•ì¸
    if response.status_code == 200:
        # JSON í¬ë§·ìœ¼ë¡œ íŒŒì‹±
        data = format_candidate_info(response.json())
        return data
    else:
        return f"API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìƒíƒœ ì½”ë“œ: {response.status_code}"
    
def find_candidate_info(í›„ë³´ì_ì´ë¦„):
    url = f"http://info.nec.go.kr/search/searchCandidate.xhtml?searchKeyword={í›„ë³´ì_ì´ë¦„}"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # "data-election-name"="20240410"ì„ í¬í•¨í•˜ëŠ” ëª¨ë“  íƒœê·¸ ì°¾ê¸°
    election_infos = soup.find_all(attrs={"data-election-name": "20240410"})
    
    # ê° <div> íƒœê·¸ì˜ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ìˆ˜ì§‘
    texts = [div.get_text(strip=True) for div in election_infos]
    
    # ë¦¬ìŠ¤íŠ¸ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©
    final_text = ' '.join(texts)

    # "ì„ ê±°ì •ë³´"ë¼ëŠ” ë‹¨ì–´ê°€ ìˆëŠ” ì¸ë±ìŠ¤ ì°¾ê¸°
    index_of_election_info = final_text.find("ë°”ë¡œê°€ê¸°")

    # "ë°”ë¡œê°€ê¸°"ë¼ëŠ” ë‹¨ì–´ ì´ì „ì˜ í…ìŠ¤íŠ¸ë§Œì„ ë‚¨ê¸°ë„ë¡ ìŠ¬ë¼ì´ì‹±
    if index_of_election_info != -1:  # "ë°”ë¡œê°€ê¸°"ë¼ëŠ” ë‹¨ì–´ê°€ ì¡´ì¬í•˜ë©´
        final_text = final_text[:index_of_election_info]
    else:
        # "ë°”ë¡œê°€ê¸°"ë¼ëŠ” ë‹¨ì–´ê°€ ì—†ìœ¼ë©´ final_textëŠ” ë³€ê²½í•˜ì§€ ì•ŠìŒ
        pass

    # ì„ ê±°êµ¬ ì´ë¦„ì„ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ë¡œì§
    for election_info in election_infos:
        # í•´ë‹¹ íƒœê·¸ ë‚´ì—ì„œ class="t"ë¥¼ ê°€ì§„ íƒœê·¸ ì°¾ê¸°
        # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¡œ election_infoì˜ í˜•ì œ íƒœê·¸ë“¤ ì¤‘ì—ì„œ class="t"ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        # ì‹¤ì œ êµ¬ì¡°ì— ë”°ë¼ next_sibling, find_parent, find ë“±ì„ ì ì ˆíˆ ì‚¬ìš©í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        target_div = election_info.find(class_='t')
        
        if target_div:
            # ì›í•˜ëŠ” í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text_parts = target_div.get_text(strip=True).split('/')
            if text_parts:
                # ë§ˆì§€ë§‰ ë¶€ë¶„ì´ ì›í•˜ëŠ” í…ìŠ¤íŠ¸
                target_text = text_parts[-1].strip()
            else:
                return "ì„ ê±°êµ¬ ì´ë¦„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        sibling = election_info.find_next_sibling(class_='list')
            
        while sibling:
            if 'list' in sibling.get('class', []):
                list_text = sibling.get_text(strip=True)
                # "ìì„¸íˆë³´ê¸°"ë¼ëŠ” ë‹¨ì–´ ì´ì „ì˜ í…ìŠ¤íŠ¸ë§Œì„ ë‚¨ê¸°ë„ë¡ ìŠ¬ë¼ì´ì‹±
                index_of_shortcut = list_text.find("ìì„¸íˆë³´ê¸°")
                if index_of_shortcut != -1:
                    list_text = list_text[:index_of_shortcut]
                    final_text += f"{list_text} "
                # ë‹¤ìŒ í˜•ì œ ìš”ì†Œë¡œ ì´ë™
                sibling = sibling.find_next_sibling(class_='list')
            else:
                # 'list' í´ë˜ìŠ¤ê°€ ì•„ë‹ˆë©´ ë°˜ë³µ ì¤‘ì§€
                break
    if final_text:
        #final_text += f"4ì›” ì´ì„  ì¶œë§ˆí•˜ëŠ” ì„ ê±°êµ¬: {target_text}"
        return final_text.strip()
    else:
        return "ì§€ì •ëœ ì„ ê±° ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” í›„ë³´ì ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."    

def complete_prompt(question):
    prompt = f"""
    
    Complete the user's prompt by adding words to make it an Korean interrogative sentence that very clearly reveals the user's intent.

    Prompt: ê¹€ì€í˜œ í›„ë³´ëŠ” ì–´ë””ì„œ ì¶œë§ˆ?
    Complete sentence: ê¹€ì€í˜œ í›„ë³´ëŠ” ì´ë²ˆ ì´ì„ ì—ì„œ ì–´ëŠ ì„ ê±°êµ¬ì—ì„œ ì¶œë§ˆí–ˆë‚˜ìš”?

    Prompt: ì„œìš¸ ë§ˆí¬ì˜ í›„ë³´ë“¤ì€? 
    Complete sentence: ì„œìš¸ ë§ˆí¬ì—ì„œ ì¶œë§ˆí•œ í›„ë³´ë“¤ì€ ëˆ„êµ¬ì¸ê°€ìš”?

    Prompt: ì›í¬ë£¡ ì „ ì¥ê´€ì˜ ì´ë ¥ì€?
    Complete sentence: ì›í¬ë£¡ ì „ ì¥ê´€ì˜ í›„ë³´ ë“±ë¡ ì´ë ¥ì€ ë¬´ì—‡ì¸ê°€ìš”? 

    Prompt: ì‚¬ì „íˆ¬í‘œëŠ” ì–¸ì œ?
    Complete sentence: ì‚¬ì „íˆ¬í‘œì˜ ë‚ ì§œëŠ” ì–¸ì œì¸ê°€ìš”?

    Prompt: íˆ¬í‘œí•  ë•Œ ì¤€ë¹„ë¬¼?
    Complete sentence: ì„ ê±°ì—ì„œ íˆ¬í‘œë¥¼ í•  ë•Œ í•„ìš”í•œ ì¤€ë¹„ë¬¼ì€ ë¬´ì—‡ì¸ê°€ìš”?

    Prompt:  {question}
    Complete sentence:
    """

    response = client.completions.create(
        model="gpt-3.5-turbo-instruct",
        prompt=prompt,
        max_tokens=40,
        temperature=1.0
    )

    # ì‘ë‹µì—ì„œ ì˜ë„ì™€ ì—”í‹°í‹° ì¶”ì¶œ
    response_text = response.choices[0].text.strip().strip('"')
    cleaned_question = response_text.replace("Complete", "").replace("sentence", "").replace(":", "").strip()
    response_lines = cleaned_question.split('\n')
    full_question = response_lines[0] if len(response_lines) > 0 else "ì§ˆë¬¸ ì—†ìŒ"
    
    return full_question

def classify_intent_and_entities(question):
    # ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
    prompt = f"""
    ë‹¤ìŒì€ êµ­íšŒì˜ì›ì„ ê±°(ì´ì„ )ì— ê´€í•´ ì‚¬ìš©ìë“¤ì´ ì§ˆë¬¸í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì—ì„œ ì¶”ì¶œí•œ ì˜ë„ì™€ ì—”í‹°í‹°ì˜ ì˜ˆì‹œë“¤ì…ë‹ˆë‹¤:

    ì§ˆë¬¸: ì„ì¢…ì„ì€ ì–´ë””ì„œ ì¶œë§ˆí–ˆë‹ˆ?
    ì˜ë„: í›„ë³´ì ì •ë³´ ì¡°íšŒ
    ì—”í‹°í‹°: ì„ì¢…ì„

    ì§ˆë¬¸: ê¹€ì€í˜œ í›„ë³´ì˜ ì¶œë§ˆ ì •ë³´ëŠ”?
    ì˜ë„: í›„ë³´ì ì •ë³´ ì¡°íšŒ
    ì—”í‹°í‹°: ê¹€ì€í˜œ

    ì§ˆë¬¸: ì›í¬ë£¡ í›„ë³´ì˜ ê³µì•½ì€?
    ì˜ë„: í›„ë³´ì ê³µì•½ ì¡°íšŒ
    ì—”í‹°í‹°: ì›í¬ë£¡
    
    ì§ˆë¬¸: ì„œìš¸ ì†¡íŒŒì— ì–´ë–¤ ì„ ê±°êµ¬ê°€ ìˆë‚˜ìš”?
    ì˜ë„: ì„ ê±°êµ¬ ì¡°íšŒ
    ì—”í‹°í‹°: ì„œìš¸ ì†¡íŒŒ

    ì§ˆë¬¸: ë¶€ì‚° í•´ìš´ëŒ€ í›„ë³´ëŠ”?
    ì˜ë„: í›„ë³´ì ì •ë³´ ì¡°íšŒ
    ì—”í‹°í‹° ë¶€ì‚° í•´ìš´ëŒ€

    ì§ˆë¬¸: ì„œìš¸ ë§ˆí¬ì—ì„œ ì¶œë§ˆí•œ í›„ë³´ìë“¤ì€ ëˆ„êµ¬?
    ì˜ë„: í›„ë³´ì ì •ë³´ ì¡°íšŒ
    ì—”í‹°í‹°: ì„œìš¸ ë§ˆí¬

    ì§ˆë¬¸: ì´ë²ˆ ì´ì„ ì— ì–´ë–¤ ì •ë‹¹ë“¤ì´ ì°¸ì—¬í•˜ë‚˜ìš”?
    ì˜ë„: ì •ë‹¹ ì •ë³´ ì¡°íšŒ
    ì—”í‹°í‹°: ì—†ìŒ

    ì§ˆë¬¸: ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹ì˜ ì£¼ìš” ê³µì•½ì€ ë¬´ì—‡ì¸ê°€ìš”?
    ì˜ë„: ê³µì•½ ë° ì •ì±… ì¡°íšŒ
    ì—”í‹°í‹°: ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹

    ì§ˆë¬¸: íˆ¬í‘œëŠ” ì–´ë–»ê²Œ í•˜ë‚˜ìš”?
    ì˜ë„: ì„ ê±°ì •ë³´ ë° íˆ¬í‘œ ë°©ë²• ì•ˆë‚´
    ì—”í‹°í‹°: ì—†ìŒ

    ì§ˆë¬¸: ì‚¬ì „íˆ¬í‘œëŠ” ì–¸ì œì¸ê°€ìš”?
    ì˜ë„: ì„ ê±°ì •ë³´ ë° íˆ¬í‘œ ì¼ì • ì¡°íšŒ
    ì—”í‹°í‹°: ì‚¬ì „íˆ¬í‘œ

    ì§ˆë¬¸: íˆ¬í‘œí•  ë•Œ í•„ìš”í•œ ì¤€ë¹„ë¬¼ì€?
    ì˜ë„: ì„ ê±°ì •ë³´ ë° íˆ¬í‘œ ê·œì • ì•ˆë‚´
    ì—”í‹°í‹°: íˆ¬í‘œ, ì¤€ë¹„ë¬¼

    ì§ˆë¬¸: ì„ ê±°ë²•ì— ë”°ë¥¸ í›„ë³´ì ìê²©ì€ ë¬´ì—‡ì¸ê°€ìš”?
    ì˜ë„: ì„ ê±°ë²• ë° ê·œì • ì•ˆë‚´
    ì—”í‹°í‹°: í›„ë³´ì ìê²©

    ì§ˆë¬¸: í›„ë³´ê°€ ëˆ ë°›ìœ¼ë©´ ì–´ë–¤ ì²˜ë²Œì„ ë°›ë‚˜ìš”?
    ì˜ë„: ë¶€ì •í–‰ìœ„ ë° ì²˜ë²Œ ì¡°íšŒ
    ì—”í‹°í‹°: í›„ë³´, ëˆ, ì²˜ë²Œ

    ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ì„œ ì•„ë˜ ì‚¬ìš©ìì˜ ì§ˆë¬¸ìœ¼ë¡œë¶€í„° ì˜ë„ì™€ ì—”í‹°í‹°ë¥¼ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:

    ì‚¬ìš©ìì˜ ì§ˆë¬¸: "{question}"
    ì˜ë„:
    ì—”í‹°í‹°:
    """

    response = client.completions.create(
        model="gpt-3.5-turbo-instruct",
        prompt=prompt,
        max_tokens=100,
        temperature=1.0
    )

    # ì‘ë‹µì—ì„œ ì˜ë„ì™€ ì—”í‹°í‹° ì¶”ì¶œ
    response_text = response.choices[0].text.strip().strip('"')
    lines = response_text.split('\n')
    if len(lines) > 0 and ": " in lines[0]:
        intent = lines[0].split(": ")[1]
    else:
        intent = "ì—†ìŒ"
    if len(lines) > 1 and ": " in lines[1]:
        entity = lines[1].split(": ")[1]
    else:
        entity = "ì—†ìŒ"
    total_tokens = response.usage.total_tokens    
    return intent, entity, total_tokens 

def choose_tool_with_gpt_detailed(question, intent):
    # ì˜ë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ ë„êµ¬ ì„ íƒì„ ìœ„í•œ ìƒì„¸ ì„¤ëª…ì´ í¬í•¨ëœ í”„ë¡¬í”„íŠ¸
    prompt = f"""
    The following tools, such as API calls and DB access, can help you better answer user questions:

    - í›„ë³´ê°œì¸API: This is an API that allows users to search for information of requested candidate(including preliminary candidates).
    - í›„ë³´ê³µì•½API: This is an API that allows users to query election pledge information of requested candidates.
    - ë™ë„¤í›„ë³´API: This is an API that allows users to search for candidates in the constituency or requested region.
    - ì„ ê±°êµ¬DB: This is a database containing information on the names of electoral districts and administrative districts. This is essential if the user asks for a certain region.
    - ì„ ê±°ì •ë³´DB: This is a database that contains all information related to general elections, elections, voting, early voting, and vote counting. It also includes election laws and prohibitions.

    Depending on the user's questions and intentions, determine whether each tool is necessary or not. Categorize only those tools that you have judged as 'yes'.

    Questions: {question}
    Intent: {intent}
    Tools needed:
    """

    response = client.completions.create(
        model="gpt-3.5-turbo-instruct",
        prompt=prompt,
        max_tokens=120,
        temperature=1.0
    )
    
    # ì‘ë‹µì—ì„œ ì„ íƒëœ ë„êµ¬ ì¶”ì¶œ
    tools = response.choices[0].text.strip().strip('"')
    cleand_tools = tools.replace("Tools ", "").replace("needed", "").replace(":", "").strip()
    total_tokens = response.usage.total_tokens
    return cleand_tools, total_tokens

def process_based_on_chosen_tool(choosed_tool, user_entity, prompt):
    
    final_return = ""
    df_ì„ ê±°êµ¬ = st.session_state.get("df_ì„ ê±°êµ¬")
    df_ì„ ê±°ë²• = st.session_state.get("df_ì„ ê±°ë²•")

    if "í›„ë³´ê°œì¸" in choosed_tool:
        # ì‰¼í‘œë‚˜ ë¹ˆì¹¸ìœ¼ë¡œ êµ¬ë¶„
        words = re.split(r',\s*|\s+', user_entity)
        # ê° ë‹¨ì–´ë¥¼ find_candidate_info() ì…ë ¥ íŒŒë¼ë¯¸í„°ì— ë„£ì–´ í˜¸ì¶œ
        results = [find_candidate_info(word.strip()) for word in words]
        final_return += f"ì„ ê±°ê´€ë¦¬ìœ„ì›íšŒì—ì„œ {user_entity}ì˜ ì˜ˆë¹„ í›„ë³´ì ë“±ë¡ ì—¬ë¶€ë¥¼ ê²€ìƒ‰í•œ ê²°ê³¼ì…ë‹ˆë‹¤.\n\n"
        # ê°ê°ì˜ words ì™€ results ë¥¼ final_return ìŠ¤íŠ¸ë§ì— ìŒìœ¼ë¡œ append
        for word, result in zip(words, results):
            final_return += f"{word.strip()}: {result}\n\n"
    
    if "í›„ë³´ê³µì•½" in choosed_tool:
        # ì‹¤ì œ API í˜¸ì¶œ ë° ë°ì´í„° ì²˜ë¦¬ ì½”ë“œ
        final_return += "í˜„ì¬ ì˜ˆë¹„í›„ë³´ì ë“±ë¡ ê¸°ê°„ì…ë‹ˆë‹¤. ì„ ê±°ê´€ë¦¬ìœ„ì›íšŒì— í›„ë³´ì ê³µì•½ ì •ë³´ê°€ ë“±ë¡ë¼ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\n\n"
    
    if "ë™ë„¤í›„ë³´" in choosed_tool:
        user_entity_modified = user_entity.replace(",", " ")
        user_question_embedding = client.embeddings.create(input=user_entity_modified, model='text-embedding-3-small').data[0].embedding
        user_question_embedding_2d = np.array(user_question_embedding).reshape(1, -1)

        # DataFrameì˜ ê° ë¬¸ì„œ ì„ë² ë”©ì— ëŒ€í•´ ìœ ì‚¬ë„ ê³„ì‚°
        df_ì„ ê±°êµ¬['similarities'] = df_ì„ ê±°êµ¬['embeddings'].apply(lambda x: cosine_similarity([x], user_question_embedding_2d)[0][0])
        most_similar_texts = df_ì„ ê±°êµ¬.sort_values('similarities', ascending=False).iloc[0]
        final_return += f"{most_similar_texts['ì‹œë„ëª…']} {most_similar_texts['ì„ ê±°êµ¬ëª…']}ì—ì„œ ì¶œë§ˆí•œ ì˜ˆë¹„ í›„ë³´ìë“¤ì˜ ì •ë³´ì…ë‹ˆë‹¤:\n\n"
        final_return += get_candidate_info(most_similar_texts['ì„ ê±°êµ¬ëª…'], most_similar_texts['ì‹œë„ëª…'])

    if "íˆ¬í‘œì†Œ" in choosed_tool:
        # ì‹¤ì œ API í˜¸ì¶œ ë° ë°ì´í„° ì²˜ë¦¬ ì½”ë“œ
        final_return += "ì•„ì§ ì„ ê±°ê´€ë¦¬ìœ„ì›íšŒê°€ íˆ¬í‘œì†Œì— ê´€í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\n\n"
    
    if "ì„ ê±°êµ¬" in choosed_tool:

        # prompt_for_district = f"{user_entity}ì— ëŒ€í•´ì„œ ì‹œë„ëª…ì´ ë°˜ë“œì‹œ ë“¤ì–´ê°„ ê³µì‹ í–‰ì •ëª…ì¹­ìœ¼ë¡œ ì™„ì„±í•´ì¤˜."

        # response_completion = client.completions.create(
        #     model="gpt-3.5-turbo-instruct",
        #     prompt=prompt_for_district,
        #     max_tokens=30,
        #     temperature=0
        # )
        # response_text = response_completion.choices[0].text.strip().strip('"')
        user_entity_modified = user_entity.replace(",", " ")
        # ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì„ë² ë”©ì„ 2D ë°°ì—´ë¡œ ë³€í™˜
        user_question_embedding = client.embeddings.create(input=user_entity_modified, model='text-embedding-3-small').data[0].embedding
        user_question_embedding_2d = np.array(user_question_embedding).reshape(1, -1)

        # DataFrameì˜ ê° ë¬¸ì„œ ì„ë² ë”©ì— ëŒ€í•´ ìœ ì‚¬ë„ ê³„ì‚°
        df_ì„ ê±°êµ¬['similarities'] = df_ì„ ê±°êµ¬['embeddings'].apply(lambda x: cosine_similarity([x], user_question_embedding_2d)[0][0])
            
        # ìœ ì‚¬ë„ê°€ ê°€ì¥ ë†’ì€ ìƒìœ„ 5ê°œ í…ìŠ¤íŠ¸ ì°¾ê¸°
        top_5_similar_texts = df_ì„ ê±°êµ¬.sort_values('similarities', ascending=False).head(5)
        final_return += "ì„ ê±°êµ¬ì™€ ê·¸ê²ƒì— ì†í•œ í–‰ì •êµ¬ì—­ ì •ë³´ë“¤ì…ë‹ˆë‹¤. ì˜¤ëŠ” 4ì›” 10ì¼ ì—´ë¦¬ëŠ” ì œ22ëŒ€ êµ­íšŒì˜ì› ì„ ê±°ì˜ ì„ ê±°êµ¬ëŠ” ì•„ì§ í™•ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"
        for index, row in top_5_similar_texts.iterrows():
            final_return += f"ì„ ê±°êµ¬: {row['ì„ ê±°êµ¬ëª…']}\ní–‰ì •êµ¬ì—­: {row['ì‹œë„ëª…']} {row['ì‹œêµ°êµ¬ëª…']} {row['ìë©´ë™ëª…']}\n\n"
        
    if "ì •ë‹¹ì •ë³´" in choosed_tool:
        # ì‹¤ì œ DB ì¡°íšŒ ë° ë°ì´í„° ì²˜ë¦¬ ì½”ë“œ
        final_return += "ì•„ì§ ì„ ê±°ê´€ë¦¬ìœ„ì›íšŒê°€ ì„ ê±° ì°¸ì—¬ ì •ë‹¹ë“¤ì— ê´€í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\n\n"
    
    if "ì„ ê±°ì •ë³´" in choosed_tool:
        # ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì„ë² ë”©ì„ 2D ë°°ì—´ë¡œ ë³€í™˜
        user_question_embedding = client.embeddings.create(input=prompt, model='text-embedding-3-small').data[0].embedding
        user_question_embedding_2d = np.array(user_question_embedding).reshape(1, -1)

        # DataFrameì˜ ê° ë¬¸ì„œ ì„ë² ë”©ì— ëŒ€í•´ ìœ ì‚¬ë„ ê³„ì‚°
        df_ì„ ê±°ë²•['similarities'] = df_ì„ ê±°ë²•['embeddings'].apply(lambda x: cosine_similarity([x], user_question_embedding_2d)[0][0])
            
        # ìœ ì‚¬ë„ê°€ ê°€ì¥ ë†’ì€ ìƒìœ„ 5ê°œ í…ìŠ¤íŠ¸ ì°¾ê¸°
        top_5_similar_texts = df_ì„ ê±°ë²•.sort_values('similarities', ascending=False).head(2)
        final_return_ì„ ê±°ë²• = ""
        for index, row in top_5_similar_texts.iterrows():
            final_return_ì„ ê±°ë²• += f"{row['text']}\n\n"
        final_return +=  final_return_ì„ ê±°ë²•
    return final_return

st.title("ğŸ§4ì›” ì´ì„ ì„ ì•Œë ¤ì¤˜!ğŸ—³ï¸")

# ì„¸ì…˜ ìƒíƒœì— 'messages'ê°€ ì—†ìœ¼ë©´ ì´ˆê¸° ë©”ì‹œì§€ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
ì¸ì‚¬ë§ = """
ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ì´ì„  ì±—ë´‡ 'ë•¡ë•¡ì´'ì…ë‹ˆë‹¤. 
ì–¸ë¡ ì‚¬ì—ì„œ ì±—GPT ê¸°ìˆ ì´ ì–´ë–»ê²Œ í™œìš©ë  ìˆ˜ ìˆì„ì§€ SBS êµ¬ì„±ì›ë“¤ì—ê²Œ ì˜ˆì‹œë¡œ ë³´ì—¬ë“œë¦¬ê¸° ìœ„í•œ ëª©ì ìœ¼ë¡œ ê°œë°œëìŠµë‹ˆë‹¤.
ì, ê·¸ëŸ¼ ì´ì„ ì— ëŒ€í•´ ë¬´ì—‡ì„ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ì œê°€ ì—‰ëš±í•˜ê²Œ ëŒ€ë‹µí–ˆì„ ë• ì¬ì°¨ ì§ˆë¬¸í•´ì£¼ì„¸ìš”!ğŸ‘€
"""

if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": ì¸ì‚¬ë§}]
    
# ì„¸ì…˜ ìƒíƒœì— ì €ì¥ëœ ë©”ì‹œì§€ë“¤ì„ ì±„íŒ… ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì‚¬ìš©ìê°€ ì±„íŒ… ì…ë ¥ì„ í–ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
if prompt := st.chat_input():
    # Display user message in chat message container
    with st.chat_message("user"):
        st.markdown(prompt)
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})

    # íŒŒì¼ ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•œ ê²½ìš°ë§Œ ë‹¤ìš´ë¡œë“œ ì§„í–‰
    if "file_downloaded" not in st.session_state:
        with st.spinner('ì±—ë´‡ì´ ì„ ê±°DBë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤..'):
            download_and_store_df('1KJw12xawMoOd1RWOSo0ib6PkydLdwYar', 'df_ì„ ê±°êµ¬')
            download_and_store_df('1Wc_lP14JjbOUxuUgZPwdkXDB79ccVai3', 'df_ì„ ê±°ë²•')
            st.session_state["file_downloaded"] = True  # íŒŒì¼ ë‹¤ìš´ë¡œë“œ ìƒíƒœ í‘œì‹œ

    with st.spinner('ì±—ë´‡ì´ ê´€ë ¨ ìë£Œë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤..'):
        # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.
        full_question= complete_prompt(prompt)
        response_content = f"ì›ë¬¸: {prompt}  ì™„ì„±: {full_question}\n\n"

        user_intent, user_entity, c_total_tokens = classify_intent_and_entities(prompt)
        response_content += f"1ì°¨ ë¶„ë¥˜ :: {user_intent}, {user_entity}, {c_total_tokens} í† í°\n\n"

        choosed_tool, d_total_tokens = choose_tool_with_gpt_detailed(full_question, user_intent)
        response_content += f"2ì°¨ ë¶„ë¥˜ :: {choosed_tool}, {d_total_tokens} í† í°\n\n"

        result_prompt_command = process_based_on_chosen_tool(choosed_tool, user_entity, full_question)
        response_content += f"{result_prompt_command}\n\n"

        st.write(response_content)

        final_prompt_command=f"{result_prompt_command}\n\nì‚¬ìš©ìì˜ ì§ˆë¬¸: {full_question}"

    with st.chat_message("assistant"):
        # ìµœì¢… í”„ë¡¬í”„íŠ¸ ëª…ë ¹ì„ ê¸°ë°˜ìœ¼ë¡œ ì±— ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±
        stream = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Answer only with the information mentioned in the prompt. Please summarize all the answers. If you don't have the information you need to answer, reply 'ê´€ë ¨ ì •ë³´ê°€ ì—†ì–´ì„œ ë‹µë³€í•´ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'."},
                {"role": "user", "content": final_prompt_command}
            ],
            temperature=0.0,
            stream=True,
        )
        response = st.write_stream(stream)
    
    # ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬ë¥¼ ë©”ì‹œì§€ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    msg = {"role": "assistant", "content": response}
    # ì‘ë‹µ ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìƒíƒœì˜ ë©”ì‹œì§€ ëª©ë¡ì— ì¶”ê°€í•˜ê³  ì±„íŒ… ë©”ì‹œì§€ë¡œ í‘œì‹œ
    st.session_state.messages.append(msg)